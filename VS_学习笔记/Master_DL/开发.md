## 如何加载模型参数进行进一步的训练
* 保存模型时使用
```Python
torch.save({
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
}, 'checkpoint.pth')

```
* 加载模型时使用
```Python
checkpoint = torch.load('checkpoint.pth')

model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch'] + 1
loss = checkpoint['loss']

```
* 标准代码模板
```Python
import torch

# 1. 定义好你的模型
model = UNet()

# 2. 加载训练好的权重
checkpoint_path = 'depth_stone_unet.pth'  # 你的pth文件
model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))  # or map_location='cuda' if on GPU

# 3. 把模型搬到GPU（如果有）
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# 4. 重新定义优化器（比如 Adam）
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# 5. 继续训练
for epoch in range(start_epoch, start_epoch + num_epochs):
    model.train()
    running_loss = 0.0

    for batch in train_loader:
        depth, label = batch  # 你自己的数据加载逻辑
        depth = depth.to(device)
        label = label.to(device)

        optimizer.zero_grad()
        output = model(depth)
        loss = criterion(output, label)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch}, Loss: {running_loss / len(train_loader)}")

```

## 关于卷积和池化、上采样和下采样、通道数
* 下采样: 把图片或特征图缩小，降低分辨率，提取更高层次的抽象信息。
> 常见操作方式：
> MaxPooling（最大池化）:比如 2×2 池化，把 2×2 区域变成1个数字（取最大值）
> Strided Convolution（步长卷积）:用步长 > 1 的卷积直接让输出尺寸变小
* 上采样: 把特征图放大，恢复更高的空间分辨率，帮助定位细节。
> 常见操作方式：
> 最近邻插值（Nearest neighbor interpolation）
> 双线性插值（Bilinear interpolation）
> 反卷积（Transpose Convolution / Deconvolution）
> 子像素卷积（PixelShuffle）
* 上下采样的作用:
> 像 U-Net 这种结构里，下采样是为了：
> 提取“是什么”的高级语义特征（比如：这是石头还是背景？）
> 而上采样是为了：
> 精确地恢复“在哪里”的空间信息（比如：石头的准确位置轮廓）
> 所以，先下采样压缩信息 → 再上采样恢复分辨率 → 精准分割每一个像素
> 而且 U-Net 还有一个**跳跃连接（skip connection）**的设计：
> 上采样阶段，把下采样时保存的特征图直接接过来拼接，
> 这样能保留更多的局部细节，使得预测更精细！
* 通道数
> 在下采样时，我们压缩了空间信息，为了让模型学到更丰富的特征，所以需要增加通道数来补充信息，通道多了，就能学更多不同的特征。
> 在上采样时，我们恢复空间分辨率，关注的是哪里是石头/不是石头这种最终的分类信息，所以可以减少通道数，专注于少数几类输出。
* 通道数如何变化
> 通道数增多: 多个卷积核对同一张图片跑结果，并在通道维度上堆叠起来，每个卷积核关注的重点不同，比如边缘、角点、纹理。
> 通道数减少: 每个新的卷积核，会对所有输入通道进行卷积加权求和。
